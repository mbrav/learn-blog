---
layout: post
title: "Reflections on AI"
date: "2017-04-26 16:15:46 -0400"
tags: [AI, biology, evolution, idea, opinion, future, intelligence, automation]
image: https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Classification_of_images_progress_human.png/640px-Classification_of_images_progress_human.png
excerpt: "The development of (AI) Artificial Intelligence is following the same rules that natural selection has. Will it succeed?"
---


After having all kinds of thoughts about AI, particularly after reading Nick Bostrom's *Superintellegence* a few months ago, I stumbled on Aeon's article *Raising Good Robots* by Regina Rini.[^davis] The article made me reflect on my beliefs on AI.

I think that an AI more intelligent than a human in every single domain — *will* eventually become a reality if the current technologic trends and socio-economic stability continues. Even if you assume any rate of progression, AI is no longer a question of *if*, it becomes a question of *when*. I don't think anyone today can give an answer to the question of *when* an AI breakthrough will occur, but I think it is reasonable to say that it *will* eventually occur, rather than not occur. Especially under the current pace of technologic advancement.

Now, this is the basis of my belief which I think is within these schools of beliefs on AI:[^Floridi]

**Singularitarianism** — People who believe in the invention of artificial superintelligence that will trigger runaway technological growth, resulting in unfathomable changes to human civilization.[^singular]

**AItheism** (*AI-atheism*) — Disbelievers, who don't think that an artificial superintelligencee is possible.

Now, I can consider myself to be closer to the singularitarianist group. While there are plenty of reasons and arguments out there arguing for this view, I have come up with my own which attempts to illustrate why AI lies within the human future.

## Natural Evolution

My reason comes from a rule that allowed life to proliferate on Earth 3 billions ago in the first place. The very fact that a sentient, comprehending, and relatively intelligent living being can read and comprehend these words (assuming your are not robot), who 3 billion years ago was nothing but a part of the Earth's primeval ocean — is something that I think slips past many minds when it comes to thinking about the possibility of creating non-biologic intelligence.   

Natural Evolution proves that intelligent life can spawn from a primeval soup of amino acids and molecules. It took more than 3 billion years for single celled organisms to evolve into *Homo Sapiens*, whose brain is the most complicated thing known to science (apart from only black holes and quantum theory, perhaps). The human brain is made out of small constituents; cells, molecules, which science can explain on an individual level, yet, it struggles to understand and formulate what happens when all these parts start functioning together — the enigma puzzle of the brain.

Life as we know it, is something that has arisen out of relatively simple constituents once it was given some time. I don't see a compelling reason to not believe why something intricate and complex like intelligence, will not eventually emerge out of non-biological parts. The marvel of natural selection is that is able to create sentient life out of biologic material — through the span of billions of trial and error cycles. As long as there is some _thing_ that can learn from trail and error, take advantage of iterative design, and improve; intelligence does not have to emerge just out of biology.

The same iterative technique that allowed life to emerge, are being actively used to train computers. All successes in AI are a result of "training" where the AI goes through millions of iterations before its algorithms (also known as CNN's Convolutional Neural Networks) become good at something. For biology, these iterations have taken millions of years; for a computer, it takes a few days. Humans already discovered very promising *ingredients* to non-biologic artificial intelligence, it is just a matter of time before the *recipe* is found.

## AI Evolution

Today, an AI algorithm can be trained in a matter of months, or even days, which is unlike the 3 billion years it took for life to evolve into humans. Already such algorithms are better than humans in certain areas such as IBM's speech-recognition AI, which achieved a 5.5% error rate in 2017 — very close to the error rate that humans make when understanding speech which is estimated to be at around a 5.1% error rate.[^ibm] Google in 2016 attained astounding results in AI research after its trained AI achieved a 6.1% error rate when describing images in words.[^google]

![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Classification_of_images_progress_human.png/640px-Classification_of_images_progress_human.png)  
The error rate of machine classification of images such as the one researched by Google. Red line — is the error rate of a human, which Google's algorithms have surpassed and are already applied in our daily lives.[^wiki]

Of course, these AI's are referred to as *weak AI* because they are better than humans at a very narrow domain. A *general AI* is something that is better than humans in many domains, if not all of them. General AI still seems to be nowhere close, but progress does prove that there are fewer reasons to think that it won't eventually become a reality, especially seeing that AI is already proving itself to be better than humans in many narrow domains.

Hope that this was convincing enough to point out that AI won't remain a matter of science fiction forever, and will eventually become a reality. It is only a question of *when*, and not a question of *if*. For a very interesting paper on the subject, check out Nick Bostrom's *How Long Before Superintelligence* paper written in 1997.[^bostrom]

[^singular]: [Technological singularity](https://en.wikipedia.org/wiki/Technological_singularity) from Wikipedia
[^Floridi]: Luciano Floridi in his essay [Should we be afraid of AI?](https://aeon.co/essays/true-ai-is-both-logically-possible-and-utterly-implausible) nicley categorizes the two "schools" of belief about AI proliferation into *Singularitarianism* and *AItheism*.
[^ibm]: [IBM achieves new record in speech recognition](https://www.ibm.com/blogs/research/2017/03/speech-recognition/) from [IBM Research Blog](https://www.ibm.com/us-en/)
[^google]: [Show and Tell: image captioning open sourced in TensorFlow](https://research.googleblog.com/2016/09/show-and-tell-image-captioning-open.html)
[^wiki]: Source Wikipedia - [Classification of images progress human](https://en.wikipedia.org/wiki/File:Classification_of_images_progress_human.png)
[^bostrom]: Nick Bostrom, [*How Long Before Superintelligence*](http://www.nickbostrom.com/superintelligence.html). 1997. Oxfrord Future of Humanity Institute
[^davis]: [*Raising good robots*](https://aeon.co/essays/creating-robots-capable-of-moral-reasoning-is-like-parenting) by Regina Rini. Published 18 April, 2017

*[AI]: short for Artificial Intelligence
*[CNN]: Convolutional Neural Networks
